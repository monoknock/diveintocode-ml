{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題1】スクラッチを振り返る\n",
    "```\n",
    "- 重みを初期化する必要があった\n",
    "- エポックのループが必要だった\n",
    "- 活性化関数を作る必要があった\n",
    "- optimizerを作る必要があった\n",
    "- 評価関数を作る必要があった\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題2】スクラッチとTensorFlowの対応を考える\n",
    "```\n",
    "全結合層: tf.keras.layers.Dense\n",
    "活性化関数(Sigmoid,Tanh,Softmax,ReLU): Denseの引数 activator\n",
    "optimizer(SGD,AdaGrad): model.compileのoptimizer引数\n",
    "initializer(Xavier,He): glorot_normal(seed=None)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 【問題3】3種類すべての目的変数を使用したIrisのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing as prepro\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "# 正規化 (精度向上のため)\n",
    "x = prepro.scale(x)\n",
    "# ワンホットエンコーディング\n",
    "y = to_categorical(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, shuffle=True)\n",
    "\n",
    "model = Sequential()\n",
    "# Denseの第一引数は隠れ層のニューロン数を、第二引数は入力層（がくの長さ、幅、花弁の長さ、幅）をタプル形式で指定\n",
    "model.add(Dense(16, input_shape=(4,)))\n",
    "model.add(Activation('relu'))\n",
    "# ３種の分類をしたいので出力層は3を指定\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=30, batch_size=2, verbose=0)\n",
    "# 評価\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy', '{:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題4】House Pricesのモデルを作成"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python import keras as K\n",
    "import pandas as pd\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_columns', 6)\n",
    "pd.set_option('display.max_info_rows', 6)\n",
    "\n",
    "# データセット準備\n",
    "df_base = pd.read_csv(\"../data/house-prices-advanced-regression-techniques/train.csv\")\n",
    "feature_names = [\"GrLivArea\", \"YearBuilt\"]\n",
    "y_name = \"SalePrice\"\n",
    "x = df_base.loc[:, feature_names].values\n",
    "y = df_base[y_name].values\n",
    "\n",
    "# 前処理\n",
    "# 訓練データとテストデータに分ける\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "# モデル準備\n",
    "model = K.Sequential([\n",
    "    # データの正規化（入力は１３の特徴量）\n",
    "    K.layers.BatchNormalization(input_shape=(2,)),\n",
    "    # １層目のニューラルネットワーク\n",
    "    #   活性化関数はsoftplus\n",
    "    #   kernel_regularizer正則化=>重みに制限をかける=>過学習防止\n",
    "    K.layers.Dense(units=2, activation=\"softplus\", kernel_regularizer=\"l1\"),\n",
    "    # ２層目のニューラルネットワーク\n",
    "    K.layers.Dense(units=1)\n",
    "])\n",
    "# loss=最小二乗法  optimizer=最適化に確率的勾配降下法\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n",
    "\n",
    "# 学習\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "# 予測を行う\n",
    "predicts = model.predict(x_test)\n",
    "\n",
    "# 評価\n",
    "print(model.evaluate(x_test, y_test, verbose=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題5】MNISTのモデルを作成\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# PrefetchDataset\n",
    "mnist_dataset, mnist_info = tfds.load(name=\"mnist\", with_info=True, as_supervised=True)\n",
    "# PrefetchDataset\n",
    "mnist_train, mnist_test = mnist_dataset[\"train\"], mnist_dataset['test']\n",
    "\n",
    "# EagerTensor\n",
    "# なぜtf.castを通しているのかは現段階では不明、おそらくtf内で計算しやすいオブジェクトにしているのではなかろうか\n",
    "num_valid_samples = tf.cast(0.1 * mnist_info.splits['train'].num_examples, tf.int64)\n",
    "num_test_samples = tf.cast(mnist_info.splits['test'].num_examples, tf.int64)\n",
    "\n",
    "\n",
    "# Feature Scaling 0~255 => 0~1 にスケーリングする\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# MapDataset\n",
    "scaled_train_and_valid_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "# train/validにsplit\n",
    "BUFFER_SIZE = 10000 # メモリ対策\n",
    "shuffled_train_and_valid_data = scaled_train_and_valid_data.shuffle(BUFFER_SIZE)\n",
    "valid_data = shuffled_train_and_valid_data.take(num_valid_samples)\n",
    "train_data = shuffled_train_and_valid_data.skip(num_valid_samples)\n",
    "\n",
    "\n",
    "# 負荷対策\n",
    "BATCH_SIZE = 100\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "valid_data = valid_data.batch(num_valid_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "valid_inputs, valid_targets = next(iter(valid_data))\n",
    "\n",
    "\n",
    "#\n",
    "# モデルの作成\n",
    "# 隠れ層: 2層\n",
    "# 合計: 4層\n",
    "#\n",
    "input_size = 784 # 28 * 28 * 1\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)), # 1列に変換\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='tanh'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='tanh'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer='adagrad', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "result = model.fit(train_data, epochs=10, validation_data=(valid_inputs, valid_targets), verbose =2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 評価\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n",
    "\n",
    "loss_list = result.history['loss']\n",
    "loss_list_val = result.history['val_loss']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plot_x = [i for i in range(1, len(loss_list)+1)]\n",
    "plt.plot(plot_x, loss_list, label='train')\n",
    "plt.plot(plot_x, loss_list_val, label='valid')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}