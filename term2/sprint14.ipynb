{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】公式Exampleを分担して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2947 - accuracy: 0.9143: 1s - loss: 0.4 - ETA: 1s - loss: 0.3709  - ETA: 0s - loss: 0.3\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1436 - accuracy: 0.9569: 0s - loss: 0.1450 - ac\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1073 - accuracy: 0.9675\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0861 - accuracy: 0.9737\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0725 - accuracy: 0.9775: 0s - loss: 0.0722 - accuracy: \n",
      "313/313 - 0s - loss: 0.0719 - accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 公式チュートリアル\n",
    "#\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 # feature scalingのために255で割る\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions\n",
    "tf.nn.softmax(predictions).numpy()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "# 学習\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】Iris（2値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "75/75 [==============================] - 1s 634us/step - loss: 1.2447 - accuracy: 0.4325\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 0s 604us/step - loss: 0.9525 - accuracy: 0.5011\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 0s 568us/step - loss: 0.7082 - accuracy: 0.7875\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 0s 630us/step - loss: 0.5614 - accuracy: 0.8936\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 0s 612us/step - loss: 0.4383 - accuracy: 0.8517\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 0s 806us/step - loss: 0.3427 - accuracy: 0.9326\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 0s 727us/step - loss: 0.3141 - accuracy: 0.9520\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 0s 608us/step - loss: 0.2823 - accuracy: 0.9318\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 0s 621us/step - loss: 0.2615 - accuracy: 0.9250\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 0s 599us/step - loss: 0.1688 - accuracy: 0.9761\n",
      "アヤメ 2値分類 Accuracy 0.92\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import pandas as pd\n",
    "\n",
    "# データ準備\n",
    "iris_dataset = datasets.load_iris()\n",
    "x = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "y = pd.Series(iris_dataset.target, name=\"y\")\n",
    "df_train = x.join(y).query('y in (1,2)') # yを2値に変換\n",
    "x = df_train.drop([\"y\"],  axis=1)\n",
    "y = df_train[\"y\"]\n",
    "\n",
    "# 正規化 (精度向上のため)\n",
    "x = preprocessing.scale(x)\n",
    "\n",
    "# ワンホットエンコーディング\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "# 分割 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "\n",
    "# モデルの初期化\n",
    "model = Sequential()\n",
    "# Denseの第一引数は隠れ層のニューロン数を、\n",
    "# 第二引数は入力層（がくの長さ、幅、花弁の長さ、幅）をタプル形式で指定\n",
    "model.add(Dense(16, input_shape=(4,)))\n",
    "model.add(Activation('relu'))\n",
    "# ３種の分類をしたいので出力層は3を指定\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax')) # Activationは活性化関数\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "# epochs: 整数でモデルを訓練するエポック数（x・y全データの反復）\n",
    "# batch_size: 設定したサンプル数ごとに勾配の更新\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=1, verbose=1)\n",
    "\n",
    "# 推定/評価\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('アヤメ 2値分類 Accuracy', '{:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】Iris（多値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "112/112 [==============================] - 1s 635us/step - loss: 1.1382 - accuracy: 0.3514\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 0s 624us/step - loss: 0.7674 - accuracy: 0.8693\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 0s 589us/step - loss: 0.5451 - accuracy: 0.9092\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 0s 584us/step - loss: 0.4070 - accuracy: 0.8938\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 0s 662us/step - loss: 0.3254 - accuracy: 0.9040\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 0s 631us/step - loss: 0.3767 - accuracy: 0.8558\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 0s 585us/step - loss: 0.3342 - accuracy: 0.8506\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 0s 590us/step - loss: 0.2994 - accuracy: 0.9002\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 0s 604us/step - loss: 0.2745 - accuracy: 0.9038\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 0s 580us/step - loss: 0.2534 - accuracy: 0.9077\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 0s 585us/step - loss: 0.2167 - accuracy: 0.9288\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 0s 570us/step - loss: 0.2316 - accuracy: 0.9193\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 0s 620us/step - loss: 0.2470 - accuracy: 0.8884\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 0s 625us/step - loss: 0.2199 - accuracy: 0.9117\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 0s 653us/step - loss: 0.2531 - accuracy: 0.8957\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 0s 629us/step - loss: 0.1879 - accuracy: 0.9447\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 0s 625us/step - loss: 0.1433 - accuracy: 0.9701\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 0s 742us/step - loss: 0.1301 - accuracy: 0.9774\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 0s 683us/step - loss: 0.1414 - accuracy: 0.9552\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 0s 653us/step - loss: 0.1523 - accuracy: 0.9565\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 0s 650us/step - loss: 0.1217 - accuracy: 0.9603\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 0s 692us/step - loss: 0.1129 - accuracy: 0.9636\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 0s 605us/step - loss: 0.1276 - accuracy: 0.9612\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 0s 627us/step - loss: 0.1155 - accuracy: 0.9794\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 0s 602us/step - loss: 0.1054 - accuracy: 0.9772\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 0s 641us/step - loss: 0.1182 - accuracy: 0.9646\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 0s 601us/step - loss: 0.1110 - accuracy: 0.9868\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 0s 750us/step - loss: 0.1251 - accuracy: 0.9692\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 0s 619us/step - loss: 0.0895 - accuracy: 0.9957\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 0s 689us/step - loss: 0.1041 - accuracy: 0.9760\n",
      "Accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "# 参考: https://chusotsu-program.com/tensorflow-keras-iris/\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    " \n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 正規化 (精度向上のため)\n",
    "x = preprocessing.scale(x)\n",
    "\n",
    "# ワンホットエンコーディング\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "# 分割 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "\n",
    "# モデルの初期化\n",
    "model = Sequential()\n",
    "# Denseの第一引数は隠れ層のニューロン数を、\n",
    "# 第二引数は入力層（がくの長さ、幅、花弁の長さ、幅）をタプル形式で指定\n",
    "model.add(Dense(16, input_shape=(4,)))\n",
    "model.add(Activation('relu'))\n",
    "# ３種の分類をしたいので出力層は3を指定\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax')) # Activationは活性化関数\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# epochs: 整数でモデルを訓練するエポック数（x・y全データの反復）\n",
    "# batch_size: 設定したサンプル数ごとに勾配の更新\n",
    "model.fit(x_train, y_train, epochs=30, batch_size=1, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy', '{:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】House PricesをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 0s 784us/step - loss: 180808.8281\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 0s 738us/step - loss: 180808.7188\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 0s 687us/step - loss: 180808.5625\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 0s 699us/step - loss: 180808.3594\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 0s 636us/step - loss: 180808.1875\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 0s 705us/step - loss: 180807.9688\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 0s 718us/step - loss: 180807.7344\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 0s 635us/step - loss: 180807.4688\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 0s 723us/step - loss: 180807.1719\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 0s 672us/step - loss: 180806.8281\n",
      "10/10 [==============================] - 0s 669us/step - loss: 181369.5469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "181369.546875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python import keras as K\n",
    "import pandas as pd\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_columns', 6)\n",
    "pd.set_option('display.max_info_rows', 6)\n",
    "\n",
    "# データセット準備\n",
    "df_base = pd.read_csv(\"../data/house-prices-advanced-regression-techniques/train.csv\")\n",
    "feature_names = [\"GrLivArea\", \"YearBuilt\"]\n",
    "y_name = \"SalePrice\"\n",
    "x = df_base.loc[:, feature_names].values\n",
    "y = df_base[y_name].values\n",
    "\n",
    "# 前処理\n",
    "# 訓練データとテストデータに分ける\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "# モデル準備\n",
    "model = K.Sequential([\n",
    "    # データの正規化（入力は１３の特徴量）\n",
    "    K.layers.BatchNormalization(input_shape=(2,)),\n",
    "    # １層目のニューラルネットワーク\n",
    "    #   活性化関数はsoftplus\n",
    "    #   kernel_regularizer正則化=>重みに制限をかける=>過学習防止\n",
    "    K.layers.Dense(units=2, activation=\"softplus\", kernel_regularizer=\"l1\"),\n",
    "    # ２層目のニューラルネットワーク\n",
    "    K.layers.Dense(units=1)\n",
    "])\n",
    "# loss=最小二乗法  optimizer=最適化に確率的勾配降下法\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n",
    "\n",
    "# 学習\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "# 予測を行う\n",
    "predicts = model.predict(x_test)\n",
    "\n",
    "# 評価\n",
    "display(model.evaluate(x_test, y_test, verbose=1))\n",
    "\n",
    "# 結果をグラフ表示する。\n",
    "# result = pd.DataFrame({\n",
    "#     \"predict\": np.reshape(predicts, (-1,)),   # 2次元データを1次元データに変換\n",
    "#     \"actual\": y_test\n",
    "# })\n",
    "# result.plot.scatter(x=\"actual\", y=\"predict\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】MNISTをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 3s - loss: 0.4242 - accuracy: 0.8815 - val_loss: 0.2284 - val_accuracy: 0.9332\n",
      "Epoch 2/5\n",
      "540/540 - 2s - loss: 0.1926 - accuracy: 0.9443 - val_loss: 0.1588 - val_accuracy: 0.9543\n",
      "Epoch 3/5\n",
      "540/540 - 2s - loss: 0.1432 - accuracy: 0.9577 - val_loss: 0.1308 - val_accuracy: 0.9620\n",
      "Epoch 4/5\n",
      "540/540 - 1s - loss: 0.1142 - accuracy: 0.9660 - val_loss: 0.1134 - val_accuracy: 0.9675\n",
      "Epoch 5/5\n",
      "540/540 - 2s - loss: 0.1000 - accuracy: 0.9699 - val_loss: 0.0952 - val_accuracy: 0.9712\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1081 - accuracy: 0.9661\n",
      "Test loss: 0.11. Test accuracy: 96.61%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# PrefetchDataset\n",
    "mnist_dataset, mnist_info = tfds.load(name=\"mnist\", with_info=True, as_supervised=True)\n",
    "# PrefetchDataset\n",
    "mnist_train, mnist_test = mnist_dataset[\"train\"], mnist_dataset['test']\n",
    "\n",
    "# EagerTensor\n",
    "# なぜtf.castを通しているのかは現段階では不明、おそらくtf内で計算しやすいオブジェクトにしているのではなかろうか\n",
    "num_valid_samples = tf.cast(0.1 * mnist_info.splits['train'].num_examples, tf.int64)\n",
    "num_test_samples = tf.cast(mnist_info.splits['test'].num_examples, tf.int64)\n",
    "\n",
    "\n",
    "# Feature Scaling 0~255 => 0~1 にスケーリングする\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# MapDataset\n",
    "scaled_train_and_valid_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "# train/validにsplit\n",
    "BUFFER_SIZE = 10000 # メモリ対策\n",
    "shuffled_train_and_valid_data = scaled_train_and_valid_data.shuffle(BUFFER_SIZE)\n",
    "valid_data = shuffled_train_and_valid_data.take(num_valid_samples)\n",
    "train_data = shuffled_train_and_valid_data.skip(num_valid_samples)\n",
    "\n",
    "# 負荷対策\n",
    "BATCH_SIZE = 100\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "valid_data = valid_data.batch(num_valid_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "valid_inputs, valid_targets = next(iter(valid_data))\n",
    "\n",
    "#\n",
    "# モデルの作成\n",
    "# 隠れ層: 2層\n",
    "# 合計: 4層\n",
    "#\n",
    "input_size = 784 # 28 * 28 * 1\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)), # 1列に変換\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "model.fit(train_data, epochs=5, validation_data=(validation_inputs, validation_targets), verbose =2)\n",
    "\n",
    "# 評価\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
