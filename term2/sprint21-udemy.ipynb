{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Review  Liked\n",
      "0                             Wow... Loved this place.      1\n",
      "1                                   Crust is not good.      0\n",
      "2            Not tasty and the texture was just nasty.      0\n",
      "3    Stopped by during the late May bank holiday of...      1\n",
      "4    The selection on the menu was great and so wer...      1\n",
      "..                                                 ...    ...\n",
      "995  I think food should have flavor and texture an...      0\n",
      "996                           Appetite instantly gone.      0\n",
      "997  Overall I was not impressed and would not go b...      0\n",
      "998  The whole experience was underwhelming, and I ...      0\n",
      "999  Then, as if I hadn't wasted enough of my life ...      0\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/monoknock/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "dataset = pd.read_csv('../data/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\n",
    "print(dataset)\n",
    "nltk.download('stopwords')\n",
    "corpus = []\n",
    "for i in range(0, len(dataset['Review'])):\n",
    "    # テキストクリーニング: 余計な記号などを排除\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    # テキストクリーニング: 大文字を小文字に変換\n",
    "    review = review.lower()\n",
    "    # 行ごとに単語を配列化\n",
    "    review = review.split()\n",
    "    # ステミング (語形が「see」「saw」「seen」のように変化する単語に対して語幹に揃える)\n",
    "    ps = PorterStemmer()\n",
    "    # ストップワード除去\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    # 配列を文字列に直す\n",
    "    review = ' '.join(review)\n",
    "    # 行ごとに配列に詰める\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 単語をカウントするクラス\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "# 変換\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 1].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0\n",
      " 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1\n",
      " 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0\n",
      " 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1]\n",
      "[[55 42]\n",
      " [12 91]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.73"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# ナイーブベイズ\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best', 'movie', 'ever', 'this', 'movie', 'best', 'movie', 'ever', 'hoge']\n",
      "['best', 'ever', 'hoge', 'movie', 'this']\n",
      "{'best': 0, 'movie': 3, 'ever': 1, 'this': 4, 'hoge': 2}\n",
      "[[1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(max_features = 1500)\n",
    "hoge = \"best movie ever!!!!! this movie best movie ever!!!!! hoge\".lower().replace('!', '').split()\n",
    "a = cv.fit(hoge)\n",
    "b = cv.transform(hoge).toarray()\n",
    "print(hoge)\n",
    "print(a.get_feature_names())\n",
    "# カラム名と結果のindexの対応が返る\n",
    "print(a.vocabulary_)\n",
    "# 1単語とレコードが対応している\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}