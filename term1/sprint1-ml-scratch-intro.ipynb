{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】クロスバリデーション\n",
    "```\n",
    "事前学習期間は検証データを分割しておき、それに対して指標値を計算することで検証を行っていました。しかし、分割の仕方により精度は変化します。実践的には クロスバリデーション を行います。\n",
    "具体的には分割を複数回行い、それぞれに対して学習と検証を行う方法です。複数回の分割を行う関数はscikit-learnにKFoldとして用意されています。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# データ前準備\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_info_columns', 150)\n",
    "pd.set_option('display.max_info_rows', 150)\n",
    "\n",
    "df_base = pd.read_csv(\"../data/home-credit-default-risk/application_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6267089973920692"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最初の値\n",
    "x_names = [\n",
    "    \"DAYS_EMPLOYED\", \"REGION_RATING_CLIENT_W_CITY\", \"FLAG_DOCUMENT_3\", \"REGION_RATING_CLIENT\", \"DAYS_BIRTH\",\n",
    "    \"AMT_REQ_CREDIT_BUREAU_YEAR\", \"OBS_30_CNT_SOCIAL_CIRCLE\", \"OBS_60_CNT_SOCIAL_CIRCLE\", \"OWN_CAR_AGE\", \"DAYS_ID_PUBLISH\",\n",
    "    \"DEF_30_CNT_SOCIAL_CIRCLE\", \"FLAG_DOCUMENT_7\", \"DEF_60_CNT_SOCIAL_CIRCLE\", \"DAYS_LAST_PHONE_CHANGE\",\n",
    "]\n",
    "y_name = \"TARGET\"\n",
    "df = df_base.loc[:, np.append(x_names, y_name)]\n",
    "# null処理 \n",
    "df = df.dropna().reset_index(drop=True)\n",
    "x = df.loc[:, x_names]\n",
    "y = df[y_name]\n",
    "\n",
    "#\n",
    "# クロスバリデーション\n",
    "#\n",
    "import lightgbm as lgbm\n",
    "lgb = lgbm.LGBMRegressor()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = KFold(n_splits=4, random_state=0, shuffle=True)\n",
    "result = cross_val_score(lgb, x, y, cv = kfold, scoring=\"roc_auc\")\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7046872986572721"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_names = [\n",
    "    \"DAYS_EMPLOYED\", \"REGION_RATING_CLIENT_W_CITY\", \"FLAG_DOCUMENT_3\", \"REGION_RATING_CLIENT\", \"DAYS_BIRTH\",\n",
    "    \"AMT_REQ_CREDIT_BUREAU_YEAR\", \"OBS_30_CNT_SOCIAL_CIRCLE\", \"OBS_60_CNT_SOCIAL_CIRCLE\", \"OWN_CAR_AGE\", \"DAYS_ID_PUBLISH\",\n",
    "    \"DEF_30_CNT_SOCIAL_CIRCLE\", \"FLAG_DOCUMENT_7\", \"DEF_60_CNT_SOCIAL_CIRCLE\", \"DAYS_LAST_PHONE_CHANGE\",\n",
    "    \"EXT_SOURCE_3\"\n",
    "]\n",
    "# \"FLAG_DOCUMENT_3\" これが相関あるらしい\n",
    "\n",
    "y_name = \"TARGET\"\n",
    "df = df_base.loc[:, np.append(x_names, y_name)]\n",
    "# null処理 \n",
    "df = df.dropna().reset_index(drop=True)\n",
    "x = df.loc[:, x_names]\n",
    "y = df[y_name]\n",
    "\n",
    "#\n",
    "# クロスバリデーション\n",
    "#\n",
    "import lightgbm as lgbm\n",
    "lgb = lgbm.LGBMRegressor()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = KFold(n_splits=4, random_state=0, shuffle=True)\n",
    "result = cross_val_score(lgb, x, y, cv = kfold, scoring=\"roc_auc\")\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】グリッドサーチ\n",
    "```\n",
    "これまで分類器のパラメータは基本的にデフォルトの設定を使用していました。パラメータの詳細は今後のSprintで学んでいくことになりますが、パラメータは状況に応じて最適なものを選ぶ必要があります。パラメータを探索するために グリッドサーチ と呼ばれる総当たり的手法が一般的に利用されます。\n",
    "グリッドサーチをパイプラインの中に組み込みましょう。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7101901325016641\n",
      "{'learning_rate': 0.15, 'min_child_weight': 0, 'num_leaves': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'num_leaves': [3, 5, 7, 9, 11],\n",
    "    'min_child_weight': [0, 5, 15, 100, 300],\n",
    "    'learning_rate': [0.1, 0.15, 0.2],\n",
    "    'subsample': [0.01, 0.05, 0.1, 0.15],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lgb, param_grid=params, cv=3, scoring=\"roc_auc\")\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】Kernelからの調査\n",
    "```\n",
    "KaggleのKernelから自身にはなかったアイデアを見つけ出して、列挙してください。そして、効果があると考えられるものを検証してください。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "複数の特徴量を試しまして、EXT_SOURCE_3でapplicationを割ったのは効果がありました\n",
    "application以外のcsvから新しい特徴量を作る\n",
    "Previous_application.csvの最後の 3, 5番目の特徴量と最初の2, 4番目の特徴量のapplicationsについてそれぞれ集計は一番良いスコアになりました。\n",
    "creditannuityratio: AMTCREDIT / AMTANNUITYの割合\n",
    "credit_goods_price_ratio：AMT_CREDIT / AMT_GOODS_PRICEの割合\n",
    "credit_downpayment：AMT_GOOD_PRICE – AMT_CREDITの差異\n",
    "prev_PRODUCT_COMBINATION：一番直近の応募の特徴量\n",
    "\n",
    "参考: https://data-analysis-stats.jp/kaggle/kaggle1%e4%bd%8d%e3%81%ae%e8%a7%a3%e6%9e%90%e6%89%8b%e6%b3%95%e3%80%80%e3%80%8chome-credit-default-risk-%e5%82%b5%e5%8b%99%e4%b8%8d%e5%b1%a5%e8%a1%8c%e3%81%ae%e4%ba%88%e6%b8%ac%e3%80%8d%e2%91%a1/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】高い汎化性能のモデル\n",
    "```\n",
    "これまで学んだことを用いながら汎化性能の高いモデルを作成してください。\n",
    "今は全体の流れを掴むことを重視し、Sprintの時間内に結果を出すということも意識しましょう。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7046872986572721"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_names = [\n",
    "    \"DAYS_EMPLOYED\", \"REGION_RATING_CLIENT_W_CITY\", \"FLAG_DOCUMENT_3\", \"REGION_RATING_CLIENT\", \"DAYS_BIRTH\",\n",
    "    \"AMT_REQ_CREDIT_BUREAU_YEAR\", \"OBS_30_CNT_SOCIAL_CIRCLE\", \"OBS_60_CNT_SOCIAL_CIRCLE\", \"OWN_CAR_AGE\", \"DAYS_ID_PUBLISH\",\n",
    "    \"DEF_30_CNT_SOCIAL_CIRCLE\", \"FLAG_DOCUMENT_7\", \"DEF_60_CNT_SOCIAL_CIRCLE\", \"DAYS_LAST_PHONE_CHANGE\",\n",
    "    \"EXT_SOURCE_3\"\n",
    "]\n",
    "y_name = \"TARGET\"\n",
    "df = df_base.loc[:, np.append(x_names, y_name)]\n",
    "# null処理 \n",
    "df = df.dropna().reset_index(drop=True)\n",
    "x = df.loc[:, x_names]\n",
    "y = df[y_name]\n",
    "\n",
    "#\n",
    "# クロスバリデーション\n",
    "#\n",
    "import lightgbm as lgbm\n",
    "lgb = lgbm.LGBMRegressor()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = KFold(n_splits=4, random_state=0, shuffle=True)\n",
    "result = cross_val_score(lgb, x, y, cv = kfold, scoring=\"roc_auc\")\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
