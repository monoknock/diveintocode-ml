{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ディープニューラルネットワーク\n",
    "\n",
    "$$\n",
    "【パーセプトロン】\\\\\n",
    "f(x) = \\left\\{\\begin{array}{ll}\n",
    "0 & (w・x ≦ θ)\\\\\n",
    "1 & (w・x > θ)\n",
    "\\end{array}\\right.\\\\\n",
    "f(x) = \\left\\{\\begin{array}{ll}\n",
    "0 & (w・x - θ ≦ 0)\\\\\n",
    "1 & (w・x - θ > 0)\n",
    "\\end{array}\\right.\\\\\n",
    "b = -θ と置いて、以下のように書くこともある\\\\\n",
    "f(x) = \\left\\{\\begin{array}{ll}\n",
    "0 & (w・x + b ≦ 0)\\\\\n",
    "1 & (w・x + b > 0)\n",
    "\\end{array}\\right.\\\\\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "【活性化関数】\\\\\n",
    "シグモイド関数 \\hspace{50pt} \\sigma(e) = \\frac{1}{1+e^{-a}} \\hspace{70pt}\n",
    "微分 \\hspace{50pt} \\frac{\\partial\\sigma(a)}{\\partial a} = \\sigma(a)(1-\\sigma(a)) \\\\\n",
    "ハイパボリックタンジェント \\hspace{20pt} tanh(a) = \\frac{e^{a}-e^{-a}}{e^{a}+e^{-a}} \\hspace{40pt}\n",
    "微分 \\hspace{50pt} \\sigma \\frac{tanh(a)}{\\sigma a} = \\frac{4}{(e^{a}+e^{-a})^{2}} \\\\\n",
    "ReLu \\hspace{70pt} relu(a) = max(0,a) \\hspace{50pt}\n",
    "微分 \\hspace{30pt} \\frac{\\sigma relu(a)}{\\sigma a}  = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "0 & (a \\leq 0) \\\\\n",
    "1 & (a > 0)\n",
    "\\end{array}\n",
    "\\right.\\\\\n",
    "$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"img/activation_func.png\" width=\"800\">\n",
    "    <img src=\"img/dl_layer.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "【出力層の活性化関数】\\\\\n",
    "ソフトマックス関数: 合計したら1になるもの\\\\\n",
    "ソフトマックス関数 H(p,q) = -\\sum_{x}^{} p(x) log q(x)\\\\\n",
    "【cross entropy】\\\\\n",
    "尤度関数 \\hspace{50pt} L_i = - log( \\frac{e^{f_{yi}}}{\\sum_je^{f_j}} )\\\\\n",
    "$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"img/cnn3.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "<br><br><br>\n",
    "$$\n",
    "学習率: η\\\\\n",
    "重み: w\\\\\n",
    "バイアス: b\\\\\n",
    "小さな変化: δ (スモール デルタ)\\\\\n",
    "2つの値の差: Δ(デルタ)\\\\\n",
    "w_{ij}^{(l)}: (l-1)層のj番目のユニットからl層のi番目のユニットへの重み\\\\\n",
    "b_i^{(l)}: l層のi番目のユニットに対するバイアス\\\\\n",
    "絶対値: |x| \\left| \\frac{x}{y} \\right|\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
