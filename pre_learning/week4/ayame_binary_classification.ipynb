{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 前提\n",
    "```\n",
    "4種類の特徴量（説明変数）からアヤメの種類を推測する\n",
    "アヤメの種類を分類\n",
    "\n",
    "使うアルゴリズム\n",
    "- 最近傍法\n",
    "- ロジスティック回帰\n",
    "- SVM\n",
    "- 決定木\n",
    "- ランダムフォレスト\n",
    "\n",
    "練習する上で結果の可視化を行いたいため、特徴量は4つの中で2つだけを使う\n",
    "2次元の散布図を描き確認することができる\n",
    "\n",
    "問題を単純化するためアヤメの種類を2つだけ使う\n",
    "\n",
    "目的変数 3c2(3通り) と 特徴量 4c2(6通り) を選び方の組み合わせは合計18通り\n",
    "目的変数の種類\n",
    "    Iris setosa\n",
    "    Iris virgicolor\n",
    "    Iris virginica\n",
    "特徴量の種類\n",
    "    sepal_length\n",
    "    sepal_width\n",
    "    petal_length\n",
    "    petal_width\n",
    "\n",
    "\n",
    "実際の分析では特徴量を2つに絞るのは望ましくない。\n",
    "そのため学習や推定は多次元で行い、可視化をする際にだけ主成分分析などの特徴抽出手法を適用するといったことが行われる。\n",
    "Week3で利用した散布図行列を使い可視化することも可能。\n",
    "\n",
    "データの分析まではPandasのDataFrameを使うが、scikit-learnはNumPyのndarrayを想定して作られている。\n",
    "sklearnを使う段階でndarrayに変換を行う。\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【課題1】練習のために特徴量とカテゴリを選択\n",
    "```\n",
    "virgicolor と virginica\n",
    "sepal_length　と petal_length\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "x = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "x = x.loc[:, [\"sepal_length\", \"petal_length\"]]\n",
    "y = pd.Series(iris_dataset.target, name=\"y\")\n",
    "df_train = x.join(y).query('y in (1,2)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題2】データの分析"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 散布図\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df_train)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 箱ひげ図（boxplot）\n",
    "df_train.plot.box()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# バイオリン図（violinplot）\n",
    "plt.violinplot(df_train, showmedians=True)\n",
    "plt.xticks([1, 2, 3], df_train.columns.values)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題3】前処理・訓練データと検証データの分割"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df_train.drop([\"y\"],  axis=1)\n",
    "y = df_train[\"y\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題4】前処理・標準化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_raw = x_train\n",
    "x_test_raw = x_test\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題5】学習と推定"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "preds = []\n",
    "\n",
    "for i in [1, 2, 3, 4, 5, 9]:\n",
    "    knc = KNeighborsClassifier(n_neighbors=i)\n",
    "    knc.fit(x_train, y_train) # 学習\n",
    "    p = knc.predict(x_test) # 学習結果を元に予測\n",
    "    print(f\"{i}-nn {p}\")\n",
    "    preds.append(p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題6】評価"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4種類の指標値の意味について簡単に調査して文章でまとめる\n",
    "```\n",
    "Accuracy（正解率）\n",
    "    どれくらい成功していたかを表す単純な指標\n",
    "    100個のデータが入力されたときに、90個のデータにおいて分類が成功した場合はその分類器のAccuracyは90%\n",
    "    値が大きいほど精度が高い\n",
    "    問題\n",
    "        入力データに偏りがある場合、精度が高いにも関わらず、実際は低い場合がありうる\n",
    "\n",
    "混合行列\n",
    "    True Positiv(TP)\n",
    "        予測値: Positive 真値:Positive\n",
    "    False Positive (FP)\n",
    "        予測値: Positive 真値:Negative\n",
    "    False Negative (FN)\n",
    "        予測値: Negative 真値:Positive\n",
    "    True Negative (TN)\n",
    "        予測値: Negative 真値:Negative\n",
    "\n",
    "Precision（適合率）\n",
    "    予測値がどれくらい正確であるか\n",
    "    PrecisionとRecallはトレードオフの関係\n",
    "    「Positiveと予測したデータ」のうち、本当にPositiveであった確率\n",
    "    TP / (TP+NP)\n",
    "Recall（再現率）\n",
    "    予測値がどれくらい網羅できているか\n",
    "    PrecisionとRecallはトレードオフの関係\n",
    "    「Positiveなデータの」うち、Positiveだと予測された確率のことを指します。\n",
    "    TP / (TP+FN)\n",
    "F値\n",
    "    PrecisionとRecallのバランスが良いことが良いモデルになるため、\n",
    "    そのバランスを取りつつ評価ができる指標\n",
    "    (2*Precision*Recall)/(Precision+Recall)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = preds[4]\n",
    "print(y_test.values)\n",
    "print(pred)\n",
    "\n",
    "# scikit-learnを使い4種類の指標を計算する\n",
    "display(f1_score(y_test, pred))\n",
    "display(recall_score(y_test, pred, zero_division=1))\n",
    "display(precision_score(y_test, pred, zero_division=1))\n",
    "display(accuracy_score(y_test, pred))\n",
    "\n",
    "# 混同行列をscikit-learnを使い表示する\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "display(cm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題7】可視化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# テンプレの関数を定義\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n",
    "    \"\"\"\n",
    "    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n",
    "    背景の色が学習したモデルによる推定値から描画される。\n",
    "    散布図の点は訓練データまたは検証データである。\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        特徴量\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        ラベル\n",
    "    model : object\n",
    "        学習したモデルのインスンタスを入れる\n",
    "    step : float, (default : 0.1)\n",
    "        推定値を計算する間隔を設定する\n",
    "    title : str\n",
    "        グラフのタイトルの文章を与える\n",
    "    xlabel, ylabel : str\n",
    "        軸ラベルの文章を与える\n",
    "    target_names= : list of str\n",
    "        凡例の一覧を与える\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue']\n",
    "    contourf_color = ['pink', 'skyblue']\n",
    "    n_class = 2\n",
    "    # pred\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 可視化の関数実行\n",
    "knc = KNeighborsClassifier(n_neighbors=3)\n",
    "knc.fit(x_train, y_train) # 学習\n",
    "p = knc.predict(x_test) # 学習結果を元に予測\n",
    "\n",
    "decision_region(x_train, y_train, knc)\n",
    "decision_region(x_test, y_test, knc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題8】他の手法の学習"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 最近傍法\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "knc.fit(x_train, y_train)\n",
    "knc_p = knc.predict(x_test)\n",
    "print(f\"knc:\\t\\t\\t{knc_p}\")\n",
    "decision_region(x_test, y_test, knc)\n",
    "\n",
    "knc_score = [\n",
    "    accuracy_score(y_test, knc_p),\n",
    "    precision_score(y_test, knc_p, zero_division=1),\n",
    "    recall_score(y_test, knc_p, zero_division=1),\n",
    "    f1_score(y_test, knc_p)\n",
    "]\n",
    "\n",
    "# ロジスティック回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "lr_p = lr.predict(x_test)\n",
    "print(f\"lr :\\t\\t\\t{lr_p}\")\n",
    "decision_region(x_test, y_test, lr)\n",
    "lr_score =  [\n",
    "    accuracy_score(y_test, lr_p),\n",
    "    precision_score(y_test, lr_p, zero_division=1),\n",
    "    recall_score(y_test, lr_p, zero_division=1),\n",
    "    f1_score(y_test, lr_p)\n",
    "]\n",
    "\n",
    "\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "svcmodel = svm.SVC()\n",
    "svcmodel.fit(x_train, y_train)\n",
    "svcmodel_p = svcmodel.predict(x_test)\n",
    "print(f\"svcmodel :\\t{svcmodel_p}\")\n",
    "decision_region(x_test, y_test, svcmodel)\n",
    "svcmodel_score =  [\n",
    "    accuracy_score(y_test, svcmodel_p),\n",
    "    precision_score(y_test, svcmodel_p, zero_division=1),\n",
    "    recall_score(y_test, svcmodel_p, zero_division=1),\n",
    "    f1_score(y_test, svcmodel_p)\n",
    "]\n",
    "\n",
    "\n",
    "# 決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)\n",
    "dtc_p = dtc.predict(x_test)\n",
    "print(f\"dtc_p :\\t\\t{dtc_p}\")\n",
    "decision_region(x_test, y_test, dtc)\n",
    "dtc_score =  [\n",
    "    accuracy_score(y_test, dtc_p),\n",
    "    precision_score(y_test, dtc_p, zero_division=1),\n",
    "    recall_score(y_test, dtc_p, zero_division=1),\n",
    "    f1_score(y_test, dtc_p)\n",
    "]\n",
    "\n",
    "\n",
    "# ランダムフォレスト\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc_p = rfc.predict(x_test)\n",
    "print(f\"rfc_p :\\t\\t{rfc_p}\")\n",
    "decision_region(x_test, y_test, rfc)\n",
    "rfc_score =  [\n",
    "    accuracy_score(y_test, rfc_p),\n",
    "    precision_score(y_test, rfc_p, zero_division=1),\n",
    "    recall_score(y_test, rfc_p, zero_division=1),\n",
    "    f1_score(y_test, rfc_p)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,1, figsize=(15, 3))\n",
    "data = np.array([knc_score, lr_score, svcmodel_score, dtc_score, rfc_score])\n",
    "column_labels = np.array([\"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "row_labels = [\"KNeighborsClassifier\", \"LogisticRegression\", \"SVC\", \"DecisionTreeClassifier\", \"RandomForestClassifier\"]\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=data, colLabels=column_labels, rowLabels=row_labels, loc=\"center\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> その表と決定領域を利用して結果を簡単に考察してください。\n",
    "> どの手法がどの指標値で良かったかや、どういった決定領域になっていたかを述べてください。\n",
    "```\n",
    "概ね左から右にきれいに分割されているが、決定木だけは左部分が不規則に分断されている。\n",
    "precisionはすべて1.0なため、参考にならず。\n",
    "ほかすべての指標でLogisticRegとSVCがトップ値になっている。\n",
    "全体的にサンプルが足りないため、ブレの大きい結果となっている印象がある。\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題9】（アドバンス課題）標準化の有無の比較\n",
    "```\n",
    "前処理として標準化を行いましたが、これを行わなかった場合どのような結果が得られるでしょうか。\n",
    "各手法に対しての指標値の表と決定領域の図を作成し比較および考察を行ってください。\n",
    "考察には標準化が機械学習の前処理としてどのような意味があるかを絡めてください。\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 標準化していなパターン\n",
    "lr_raw = LogisticRegression()\n",
    "lr_raw.fit(x_train_raw, y_train)\n",
    "lr_p = lr_raw.predict(x_test_raw)\n",
    "lr_score_raw =  [\n",
    "    accuracy_score(y_test, lr_p),\n",
    "    precision_score(y_test, lr_p, zero_division=1),\n",
    "    recall_score(y_test, lr_p, zero_division=1),\n",
    "    f1_score(y_test, lr_p)\n",
    "]\n",
    "\n",
    "fig, ax =plt.subplots(1,1, figsize=(15, 3))\n",
    "data = np.array([lr_score, lr_score_raw])\n",
    "column_labels = np.array([\"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "row_labels = [\"KNeighborsClassifier\", \"KNeighborsClassifier raw\"]\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=data, colLabels=column_labels, rowLabels=row_labels, loc=\"center\")\n",
    "plt.show()\n",
    "\n",
    "decision_region(x_test, y_test, lr)\n",
    "decision_region(x_test_raw.values, y_test, lr_raw)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "▼ 考察\n",
    "標準化を行わなかった場合、正答率が少し悪くなった。\n",
    "判定がどちらか微妙だった値が、標準化によって正答側に近づいた。\n",
    "標準化が機械学習の前処理としては、値の大きさ（スケール）をあわせる効果がある。\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 【問題10】（アドバンス課題）すべての目的変数を使用して精度が高い手法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "# データの準備\n",
    "#\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# データセットの準備\n",
    "iris_dataset = load_iris()\n",
    "\n",
    "# 特徴量は\"sepal_length\", \"petal_length\" の2種類\n",
    "x = pd.DataFrame(iris_dataset.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "x = x.loc[:, [\"sepal_length\", \"petal_length\"]]\n",
    "\n",
    "# 目的変数は 0 (setosa), 1 (virgicolor), 2　(virginica)\n",
    "y = pd.Series(iris_dataset.target, name=\"y\")\n",
    "\n",
    "# 1つのdfにまとめる\n",
    "df_train = x.join(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "# 特徴量エンジニアリング: 特徴量の前処理\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# x,y を tiran,test に分割\n",
    "x = df_train.drop([\"y\"],  axis=1)\n",
    "y = df_train[\"y\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "# 標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "# x_trainで学習したscalartでx_trainとx_testを標準化\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "# 学習結果の可視化\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "def decision_region2(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['setosa', 'versicolor', 'virginica']):\n",
    "    \"\"\"\n",
    "    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n",
    "    背景の色が学習したモデルによる推定値から描画される。\n",
    "    散布図の点は訓練データまたは検証データである。\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        特徴量\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        ラベル\n",
    "    model : object\n",
    "        学習したモデルのインスンタスを入れる\n",
    "    step : float, (default : 0.1)\n",
    "        推定値を計算する間隔を設定する\n",
    "    title : str\n",
    "        グラフのタイトルの文章を与える\n",
    "    xlabel, ylabel : str\n",
    "        軸ラベルの文章を与える\n",
    "    target_names= : list of str\n",
    "        凡例の一覧を与える\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['green', 'red', 'blue']\n",
    "    contourf_color = ['lime', 'pink', 'skyblue']\n",
    "    n_class = 3 # yの種類数(クラス数)\n",
    "\n",
    "    #\n",
    "    # 2つの特徴量のmin/maxレンジから細かい単位で、すべての組み合わせのpredictを行い、それを背景色として決定境界を描く\n",
    "    #\n",
    "\n",
    "    # 特徴量2つのメッシュグリッドを作成\n",
    "    # mesh_f0, mesh_f1 ともに2次元配列\n",
    "    # 参考: https://deepage.net/features/numpy-meshgrid.html\n",
    "    x0_min  = np.min(X[:,0])\n",
    "    x0_max = np.max(X[:,0])\n",
    "    x1_min = np.min(X[:,1])\n",
    "    x1_max = np.max(X[:,1])\n",
    "    x0_range = np.arange(x0_min-0.5, x0_max+0.5, step) # sepal_length\n",
    "    x1_range = np.arange(x1_min-0.5, x1_max+0.5, step) # petal_length\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(x0_range, x1_range)\n",
    "    # 学習用に配列の形状変換\n",
    "    # ravel: 2次元配列を1次元配列にする\n",
    "    # c_: 各indexの同じ要素で1つの配列とし、2次元配列を作る\n",
    "    # 実質座標を表すようになる？\n",
    "    # len(mesh) = 172260\n",
    "    mesh = np.c_[np.ravel(mesh_f0), np.ravel(mesh_f1)]\n",
    "    # おそらく、特徴量の組み合わせを膨大に作って、予測値を算出している\n",
    "    # mesh_f0.shape: (396, 435)\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "\n",
    "    display(ListedColormap(contourf_color))\n",
    "\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    # contourf(格子点のx座標の配列, 格子点のy座標の配列, 値の配列)\n",
    "    # contourf([X, Y,] Z, [levels], **kwargs)\n",
    "    # https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contourf.html\n",
    "    # エリアの色塗り\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, levels=n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    #　境界線の強調\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, levels=n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "\n",
    "    #\n",
    "    # 引数のx,yを単純にplotする\n",
    "    #\n",
    "    unique_y = set(y) # 0, 1, 2\n",
    "    for i, target in enumerate(unique_y):  # enumerate: idxとvalueを使える\n",
    "        tgt_color = scatter_color[i]\n",
    "        tgt_label = target_names[i]\n",
    "        a = X[y==target][:, 0]  # sepal_length\n",
    "        b =  X[y==target][:, 1] # petal_length\n",
    "        plt.scatter(a, b, s=80, color=tgt_color, label=tgt_label, marker='o')\n",
    "    # 凡例表示\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches) # これだけだとバーで表示される\n",
    "    plt.legend() # これを呼ぶと丸になる 謎\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "# 各アルゴリズムを使う\n",
    "#\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 最近傍法\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors=3)\n",
    "knc.fit(x_train, y_train)\n",
    "knc_p = knc.predict(x_test)\n",
    "decision_region2(x_test, y_test, knc)\n",
    "report = classification_report(y_test, knc_p, output_dict=True)\n",
    "knc_report = [\n",
    "    report[\"accuracy\"],\n",
    "    report[\"macro avg\"][\"precision\"],\n",
    "    report[\"macro avg\"][\"recall\"],\n",
    "    report[\"macro avg\"][\"f1-score\"],\n",
    "]\n",
    "\n",
    "# ロジスティック回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "lr_p = lr.predict(x_test)\n",
    "decision_region(x_test, y_test, lr)\n",
    "report = classification_report(y_test, lr_p, output_dict=True)\n",
    "lr_report = [\n",
    "    report[\"accuracy\"],\n",
    "    report[\"macro avg\"][\"precision\"],\n",
    "    report[\"macro avg\"][\"recall\"],\n",
    "    report[\"macro avg\"][\"f1-score\"],\n",
    "]\n",
    "\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "svcmodel = svm.SVC()\n",
    "svcmodel.fit(x_train, y_train)\n",
    "svcmodel_p = svcmodel.predict(x_test)\n",
    "decision_region(x_test, y_test, svcmodel)\n",
    "report = classification_report(y_test, svcmodel_p, output_dict=True)\n",
    "svc_report = [\n",
    "    report[\"accuracy\"],\n",
    "    report[\"macro avg\"][\"precision\"],\n",
    "    report[\"macro avg\"][\"recall\"],\n",
    "    report[\"macro avg\"][\"f1-score\"],\n",
    "]\n",
    "\n",
    "# 決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)\n",
    "dtc_p = dtc.predict(x_test)\n",
    "decision_region(x_test, y_test, dtc)\n",
    "report = classification_report(y_test, dtc_p, output_dict=True)\n",
    "dtc_report = [\n",
    "    report[\"accuracy\"],\n",
    "    report[\"macro avg\"][\"precision\"],\n",
    "    report[\"macro avg\"][\"recall\"],\n",
    "    report[\"macro avg\"][\"f1-score\"],\n",
    "]\n",
    "\n",
    "# ランダムフォレスト\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc_p = rfc.predict(x_test)\n",
    "decision_region(x_test, y_test, rfc)\n",
    "report = classification_report(y_test, rfc_p, output_dict=True)\n",
    "rfc_report = [\n",
    "    report[\"accuracy\"],\n",
    "    report[\"macro avg\"][\"precision\"],\n",
    "    report[\"macro avg\"][\"recall\"],\n",
    "    report[\"macro avg\"][\"f1-score\"],\n",
    "]\n",
    "\n",
    "# 評価値の表\n",
    "disp_data = np.array([knc_report, lr_report, svc_report, dtc_report, rfc_report])\n",
    "fig, ax =plt.subplots(1,1, figsize=(15, 3))\n",
    "column_labels = np.array([\"accuracy\", \"precision(macro)\", \"recall(macro)\", \"f1(macro)\"])\n",
    "row_labels = [\"KNeighborsClassifier\", \"LogisticRegression\", \"SVC\", \"DecisionTreeClassifier\", \"RandomForestClassifier\"]\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=disp_data, colLabels=column_labels, rowLabels=row_labels, loc=\"center\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Answer最も精度の高いモデル\n",
    "マクロ平均のf1で見ると、 `LogisticrRegression` が最も良い結果となる"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}